import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, datasets
import matplotlib.pyplot as plt
import numpy as np

# --- 1. Carregar e Preparar o Dataset CIFAR-10 ---

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()

# Normalizar os pixels para o intervalo [0, 1]
x_train, x_test = x_train / 255.0, x_test / 255.0

# Definir os nomes das classes
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Vamos visualizar algumas imagens
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[i])
    plt.xlabel(class_names[y_train[i][0]])
plt.show()

# --- 2. Arquitetura 1: CNN Simples ---

model_1 = models.Sequential([
    # Camada de Entrada (Input)
    layers.Input(shape=(32, 32, 3)),
    
    # Camadas Convolucionais e de Pooling
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    # Camadas Densas (Classificação)
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax') # 10 classes de saída
])

model_1.summary()

# Compilar o Modelo 1
model_1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Treinar o Modelo 1
print("\n--- Treinando Modelo 1 ---")
history_1 = model_1.fit(x_train, y_train, epochs=10, 
                    validation_data=(x_test, y_test))

# Avaliar o Modelo 1
test_loss_1, test_acc_1 = model_1.evaluate(x_test, y_test, verbose=2)
print(f"\nAcurácia do Modelo 1 no Teste: {test_acc_1 * 100:.2f}%")


# --- 3. Arquitetura 2: CNN Mais Profunda com Regularização ---
# (Usando Batch Normalization e Dropout para combater overfitting)

model_2 = models.Sequential([
    layers.Input(shape=(32, 32, 3)),
    
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

model_2.summary()

# Compilar o Modelo 2
model_2.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Treinar o Modelo 2
print("\n--- Treinando Modelo 2 ---")
history_2 = model_2.fit(x_train, y_train, epochs=10, 
                    validation_data=(x_test, y_test))

# Avaliar o Modelo 2
test_loss_2, test_acc_2 = model_2.evaluate(x_test, y_test, verbose=2)
print(f"\nAcurácia do Modelo 2 no Teste: {test_acc_2 * 100:.2f}%")


# --- 4. Comparação dos Resultados ---

print("\n--- Comparação Final ---")
print(f"Acurácia Modelo 1 (Simples): {test_acc_1 * 100:.2f}%")
print(f"Acurácia Modelo 2 (Complexo): {test_acc_2 * 100:.2f}%")

# Plotar histórico de Acurácia
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history_1.history['accuracy'], label='Treino (Modelo 1)')
plt.plot(history_1.history['val_accuracy'], label='Validação (Modelo 1)')
plt.plot(history_2.history['accuracy'], label='Treino (Modelo 2)')
plt.plot(history_2.history['val_accuracy'], label='Validação (Modelo 2)')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend(loc='lower right')
plt.title('Acurácia de Treino e Validação')

# Plotar histórico de Perda (Loss)
plt.subplot(1, 2, 2)
plt.plot(history_1.history['loss'], label='Treino (Modelo 1)')
plt.plot(history_1.history['val_loss'], label='Validação (Modelo 1)')
plt.plot(history_2.history['loss'], label='Treino (Modelo 2)')
plt.plot(history_2.history['val_loss'], label='Validação (Modelo 2)')
plt.xlabel('Época')
plt.ylabel('Perda')
plt.legend(loc='upper right')
plt.title('Perda (Loss) de Treino e Validação')

plt.tight_layout()
plt.show()
